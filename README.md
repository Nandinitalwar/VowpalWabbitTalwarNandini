# VowpalWabbitTalwarNandini
Submission for Vowpal Wabbit

I’m excited to tackle two specific compiler optimization tasks:

1. Learning a Cost Model using the State Transition Dataset
In a research project I completed in 2020 on determining the effectiveness of artificial intelligence in Quality Assurance software testing in Nondeterministic Systems through combining Runtime Monitoring and Model-Based Testing for Software Testing, I found it exciting to discover that the use of an advanced conformance index, a tool that takes into account involved coverage criteria and assigns a weight which specifies the importance of each criterion. I want to apply this knowledge to impleted a Gated Graph Neural Network in PyTorch and use Mean Squared Error loss to train a regressor to predict the instruction count of a program using model-based testing to decrease runtime by making the environment domain-specific. 
I’m keen to explore the GCC environment’s high-dimensional action space by comparing search techniques like random search, hill climbing search, and genetic algorithm by efficiency to build domain-specific multi-objective program autotuners. I want to make program autotuning portable between projects since autotuning has been shown to achieve better or more portable performance in a number of domains. 

2. Effect of Training Set on RL
At MakeHarvard, I worked on a project called “LitCam”, a neural network written using Python, PyTorch, and OpenCV that recognizes and categorizes trash using the Google Image Recognition API. A challenge I tackled was fixing how the net incorrectly identified glass as plastic and plastic as paper, by using OpenCV’s masking function to improve the quality of the individual images, increasing accuracy by 25%. I’m excited to work on similar projects that involve the automated generation of datasets, to train PPO agents on different training sets and then evaluating their generalization performance on test sets from different domains. 
As an intern at Tesla, I wrote robust test automation suites for the center display across four models, and I want to combine this knowledge to write algorithms that generalize to benchmarks within the same dataset in CompilerGym. 
